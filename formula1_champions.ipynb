{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJ90oa2JXUY6iTqvCCnhyC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"id":"92HMiMNlWsi0","executionInfo":{"status":"ok","timestamp":1719267734484,"user_tz":-330,"elapsed":750,"user":{"displayName":"Sachintha Adikari","userId":"12128635869464309010"}}},"outputs":[],"source":["# Importing needed packages\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd"]},{"cell_type":"code","source":["# Setting up the scraping function\n","def scrape_formula1(sub_url, export_name):\n","    base_url = 'https://www.formula1.com/en/results.html/'\n","    years = range(1950, 2024)\n","\n","    # Extracting headers\n","    response = requests.get(f'https://www.formula1.com/en/results.html/1950/{sub_url}')\n","\n","    if response.status_code == 200:\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # Recognizing the table to scrape\n","        table = soup.find('table', class_='resultsarchive-table')\n","\n","        # Omitting <th> tags with class 'limiter' which creates an extra column in the scraping\n","        headers = []\n","        for th in table.find_all('th'):\n","            if 'limiter' not in th.get('class', []):\n","                headers.append(th.text.strip())\n","\n","        # Adding 'Year' to the start of the header\n","        headers.insert(0, 'Year')\n","\n","        # To store the rows as they are scraped\n","        all_rows = []\n","\n","        # Looping through the years\n","        for year in years:\n","            print(f\"Extracting for {year}\")\n","            url = f'{base_url}{year}/{sub_url}'\n","\n","            response = requests.get(url)\n","\n","            if response.status_code == 200:\n","                soup = BeautifulSoup(response.text, 'html.parser')\n","\n","                table = soup.find('table', class_='resultsarchive-table')\n","\n","                rows = []\n","                for tr in table.find_all('tr'):\n","                    cells = tr.find_all('td')\n","                    if len(cells) > 0:\n","                        row = [year] # Starting the row with the year because original table doesn't has it\n","                        for td in cells:\n","                            if 'limiter' not in td.get('class', []):\n","                                row.append(td.text.strip()) # Adding the rest of the row after the year\n","                        if len(row) == len(headers):  # Ensure the row has the same length as the headers to make sure nothing is missing\n","                            rows.append(row)\n","\n","                # Add the rows for this year to the list of all rows\n","                all_rows.extend(rows)\n","\n","            else:\n","                print(f'Failed to retrieve the webpage for year {year}. Status code: {response.status_code}')\n","\n","        # Create a DataFrame from the headers and all rows\n","        final_export = pd.DataFrame(all_rows, columns=headers)\n","\n","        # Export the DataFrame to a CSV file\n","        final_export.to_csv(f'{export_name}.csv', index=False)\n","\n","    else:\n","        print(f'Failed to retrieve the webpage. Status code: {response.status_code}')\n"],"metadata":{"id":"Xoz9BaafRnmJ","executionInfo":{"status":"ok","timestamp":1719267737035,"user_tz":-330,"elapsed":498,"user":{"displayName":"Sachintha Adikari","userId":"12128635869464309010"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Variable for driver standings\n","drivers_sub_url = 'drivers.html'\n","drivers_export = 'drivers_1950_2023'\n","scrape_formula1(drivers_sub_url, drivers_export)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"BGoXGsESVqTe","executionInfo":{"status":"error","timestamp":1719267786498,"user_tz":-330,"elapsed":46056,"user":{"displayName":"Sachintha Adikari","userId":"12128635869464309010"}},"outputId":"0b40b9e1-b706-4f31-9bf4-b466555b8c7c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting for 1950\n","Extracting for 1951\n","Extracting for 1952\n","Extracting for 1953\n","Extracting for 1954\n","Extracting for 1955\n","Extracting for 1956\n","Extracting for 1957\n","Extracting for 1958\n","Extracting for 1959\n","Extracting for 1960\n","Extracting for 1961\n","Extracting for 1962\n","Extracting for 1963\n","Extracting for 1964\n","Extracting for 1965\n","Extracting for 1966\n","Extracting for 1967\n","Extracting for 1968\n","Extracting for 1969\n","Extracting for 1970\n","Extracting for 1971\n","Extracting for 1972\n","Extracting for 1973\n","Extracting for 1974\n","Extracting for 1975\n","Extracting for 1976\n","Extracting for 1977\n","Extracting for 1978\n","Extracting for 1979\n","Extracting for 1980\n","Extracting for 1981\n","Extracting for 1982\n","Extracting for 1983\n","Extracting for 1984\n","Extracting for 1985\n","Extracting for 1986\n","Extracting for 1987\n","Extracting for 1988\n","Extracting for 1989\n","Extracting for 1990\n","Extracting for 1991\n","Extracting for 1992\n","Extracting for 1993\n","Extracting for 1994\n","Extracting for 1995\n","Extracting for 1996\n","Extracting for 1997\n","Extracting for 1998\n","Extracting for 1999\n","Extracting for 2000\n","Extracting for 2001\n","Extracting for 2002\n","Extracting for 2003\n","Extracting for 2004\n","Extracting for 2005\n","Extracting for 2006\n","Extracting for 2007\n","Extracting for 2008\n","Extracting for 2009\n","Extracting for 2010\n","Extracting for 2011\n","Extracting for 2012\n","Extracting for 2013\n","Extracting for 2014\n","Extracting for 2015\n","Extracting for 2016\n","Extracting for 2017\n","Extracting for 2018\n","Extracting for 2019\n","Extracting for 2020\n","Extracting for 2021\n","Extracting for 2022\n","Extracting for 2023\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'find_all'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-2dcf2de88047>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mresults_sub_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'results.html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresults_export\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'results_1950_2023'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscrape_formula1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_sub_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_export\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-79867af6985b>\u001b[0m in \u001b[0;36mscrape_formula1\u001b[0;34m(sub_url, export_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Omitting <th> tags with class 'limiter' which creates an extra column in the scraping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'th'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'limiter'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"]}]},{"cell_type":"code","source":["# Variable for race results\n","results_sub_url = 'races.html'\n","results_export = 'races_1950_2023'\n","scrape_formula1(results_sub_url, results_export)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIi7pAElWpzP","outputId":"b749a3c9-f652-47f3-996f-73a49bd12373"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting for 1950\n","Extracting for 1951\n","Extracting for 1952\n","Extracting for 1953\n","Extracting for 1954\n","Extracting for 1955\n","Extracting for 1956\n","Extracting for 1957\n","Extracting for 1958\n","Extracting for 1959\n","Extracting for 1960\n","Extracting for 1961\n","Extracting for 1962\n","Extracting for 1963\n","Extracting for 1964\n","Extracting for 1965\n","Extracting for 1966\n","Extracting for 1967\n","Extracting for 1968\n","Extracting for 1969\n","Extracting for 1970\n","Extracting for 1971\n","Extracting for 1972\n","Extracting for 1973\n","Extracting for 1974\n","Extracting for 1975\n","Extracting for 1976\n","Extracting for 1977\n","Extracting for 1978\n","Extracting for 1979\n","Extracting for 1980\n","Extracting for 1981\n","Extracting for 1982\n","Extracting for 1983\n","Extracting for 1984\n","Extracting for 1985\n","Extracting for 1986\n","Extracting for 1987\n","Extracting for 1988\n","Extracting for 1989\n","Extracting for 1990\n","Extracting for 1991\n","Extracting for 1992\n","Extracting for 1993\n","Extracting for 1994\n","Extracting for 1995\n","Extracting for 1996\n","Extracting for 1997\n","Extracting for 1998\n","Extracting for 1999\n","Extracting for 2000\n","Extracting for 2001\n","Extracting for 2002\n","Extracting for 2003\n","Extracting for 2004\n","Extracting for 2005\n","Extracting for 2006\n","Extracting for 2007\n","Extracting for 2008\n","Extracting for 2009\n","Extracting for 2010\n","Extracting for 2011\n","Extracting for 2012\n","Extracting for 2013\n","Extracting for 2014\n","Extracting for 2015\n","Extracting for 2016\n","Extracting for 2017\n","Extracting for 2018\n","Extracting for 2019\n","Extracting for 2020\n","Extracting for 2021\n","Extracting for 2022\n"]}]}]}